{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    \"https://aws-chatbot.es.us-central1.gcp.cloud.es.io\",\n",
    "    basic_auth=(\"elastic\",\"YTEJkgvx3NX19njbGyDF40Lo\")\n",
    "   \n",
    "\n",
    ")\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I run a web server on AWS?</td>\n",
       "      <td>To run a web server on AWS, you can use Amazon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What AWS service should I use to host a scalab...</td>\n",
       "      <td>For hosting scalable applications, consider us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How do I deploy a custom application on the cl...</td>\n",
       "      <td>To deploy a custom application, use Amazon EC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I need a dedicated environment for my applicat...</td>\n",
       "      <td>If you need dedicated resources for your appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What's the best way to get started with virtua...</td>\n",
       "      <td>Start with Amazon EC2. It offers a wide range ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            pattern  \\\n",
       "0   1                 How can I run a web server on AWS?   \n",
       "1   2  What AWS service should I use to host a scalab...   \n",
       "2   3  How do I deploy a custom application on the cl...   \n",
       "3   4  I need a dedicated environment for my applicat...   \n",
       "4   5  What's the best way to get started with virtua...   \n",
       "\n",
       "                                            response  \n",
       "0  To run a web server on AWS, you can use Amazon...  \n",
       "1  For hosting scalable applications, consider us...  \n",
       "2  To deploy a custom application, use Amazon EC2...  \n",
       "3  If you need dedicated resources for your appli...  \n",
       "4  Start with Amazon EC2. It offers a wide range ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../dataset/consolidated_data.csv\").loc[:1500]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NA values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     pattern  response\n",
       "False  False    False       1501\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the relevant field to Vector using BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ResponseVector\"] = df[\"response\"].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "      <th>ResponseVector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I run a web server on AWS?</td>\n",
       "      <td>To run a web server on AWS, you can use Amazon...</td>\n",
       "      <td>[-0.00054931047, -0.05692641, -0.0006814774, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What AWS service should I use to host a scalab...</td>\n",
       "      <td>For hosting scalable applications, consider us...</td>\n",
       "      <td>[-0.015269826, -0.012294186, -0.01100238, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How do I deploy a custom application on the cl...</td>\n",
       "      <td>To deploy a custom application, use Amazon EC2...</td>\n",
       "      <td>[-0.012933653, -0.045452587, -0.0068273027, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I need a dedicated environment for my applicat...</td>\n",
       "      <td>If you need dedicated resources for your appli...</td>\n",
       "      <td>[-0.009388072, -0.018510194, 0.0007667323, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What's the best way to get started with virtua...</td>\n",
       "      <td>Start with Amazon EC2. It offers a wide range ...</td>\n",
       "      <td>[-0.059143938, -0.017358141, -0.0022847152, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            pattern  \\\n",
       "0   1                 How can I run a web server on AWS?   \n",
       "1   2  What AWS service should I use to host a scalab...   \n",
       "2   3  How do I deploy a custom application on the cl...   \n",
       "3   4  I need a dedicated environment for my applicat...   \n",
       "4   5  What's the best way to get started with virtua...   \n",
       "\n",
       "                                            response  \\\n",
       "0  To run a web server on AWS, you can use Amazon...   \n",
       "1  For hosting scalable applications, consider us...   \n",
       "2  To deploy a custom application, use Amazon EC2...   \n",
       "3  If you need dedicated resources for your appli...   \n",
       "4  Start with Amazon EC2. It offers a wide range ...   \n",
       "\n",
       "                                      ResponseVector  \n",
       "0  [-0.00054931047, -0.05692641, -0.0006814774, 0...  \n",
       "1  [-0.015269826, -0.012294186, -0.01100238, -0.0...  \n",
       "2  [-0.012933653, -0.045452587, -0.0068273027, -0...  \n",
       "3  [-0.009388072, -0.018510194, 0.0007667323, 0.0...  \n",
       "4  [-0.059143938, -0.017358141, -0.0022847152, -0...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new index in ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexMapping import indexMapping\n",
    "\n",
    "try:\n",
    "    es.indices.create(index=\"all_patterns_v1\", mappings=indexMapping) \n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest the data into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in record_list:\n",
    "    try:\n",
    "        es.index(index=\"all_patterns_1500\", document=record, id=record[\"id\"])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 1501, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index=\"all_patterns_1500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Matching Result:\n",
      "Pattern: When does billing of my Amazon EC2 systems begin and end?\n",
      "Response: Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don't charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4759/864556165.py:11: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  res = es.knn_search(index=\"all_patterns_1500\", knn=query, source=[\"pattern\", \"response\"])\n"
     ]
    }
   ],
   "source": [
    "input_keyword = \" Billing of Amazon EC2 systems begin and end?\"\n",
    "vector_of_input_keyword = model.encode(input_keyword)\n",
    "\n",
    "query = {\n",
    "    \"field\": \"ResponseVector\",\n",
    "    \"query_vector\": vector_of_input_keyword,\n",
    "    \"k\": 1,  # Set k to 1 to get only the top result\n",
    "    \"num_candidates\": 1500,\n",
    "}\n",
    "\n",
    "res = es.knn_search(index=\"all_patterns_1500\", knn=query, source=[\"pattern\", \"response\"])\n",
    "hits = res[\"hits\"][\"hits\"]\n",
    "\n",
    "\n",
    "if hits:\n",
    "    best_match = hits[0]\n",
    "    print(\"Best Matching Result:\")\n",
    "    print(\"Pattern:\", best_match[\"_source\"][\"pattern\"])\n",
    "    print(\"Response:\", best_match[\"_source\"][\"response\"])\n",
    "else:\n",
    "    print(\"No matching results found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4759/1260241245.py:11: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_index': 'all_patterns_1500',\n",
       "  '_id': '339',\n",
       "  '_score': 0.90958804,\n",
       "  '_ignored': ['response.keyword'],\n",
       "  '_source': {'pattern': 'When does billing of my Amazon EC2 systems begin and end?',\n",
       "   'response': 'Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don\\'t charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.'}},\n",
       " {'_index': 'all_patterns_1500',\n",
       "  '_id': '340',\n",
       "  '_score': 0.84812176,\n",
       "  '_ignored': ['response.keyword'],\n",
       "  '_source': {'pattern': 'What defines billable EC2 instance usage?',\n",
       "   'response': 'Instance usages are billed for any time your instances are in a \"running\" state. If you no longer wish to be charged for your instance, you must \"stop\" or \"terminate\" the instance to avoid being billed for additional instance usage. Billing starts when an instance transitions into the running state.'}},\n",
       " {'_index': 'all_patterns_1500',\n",
       "  '_id': '343',\n",
       "  '_score': 0.8385503,\n",
       "  '_ignored': ['response.keyword'],\n",
       "  '_source': {'pattern': 'How will my monthly bill show per-second versus per-hour?',\n",
       "   'response': 'Although EC2 charges in your monthly bill will now be calculated based on a per second basis, for consistency, the monthly EC2 bill will show cumulative usage for each instance that ran in a given month in decimal hours. For example, an instance running for 1 hour 10 minutes and 4 seconds would look like 1.1677. Read this blog for an example of the detailed billing report.'}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_keyword = \"Billing of Amazon EC2 systems begin and end?\"\n",
    "vector_of_input_keyword = model.encode(input_keyword)\n",
    "\n",
    "query = {\n",
    "    \"field\" : \"ResponseVector\",\n",
    "    \"query_vector\" : vector_of_input_keyword,\n",
    "    \"k\" : 3,\n",
    "    \"num_candidates\" : 1500, \n",
    "}\n",
    "\n",
    "res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n",
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "      <th>ResponseVector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>269</td>\n",
       "      <td>Why should I use EFA?</td>\n",
       "      <td>EFA brings the scalability, flexibility, and e...</td>\n",
       "      <td>[-0.008393067, -0.043162365, -0.02907724, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>1262</td>\n",
       "      <td>How do I know in which S3 Intelligent-Tiering ...</td>\n",
       "      <td>You can use Amazon S3 Inventory to report the ...</td>\n",
       "      <td>[-0.008884707, -0.022729026, 0.010597382, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>Will vCPU limits be available in all Regions?</td>\n",
       "      <td>vCPU-based instance limits are available in al...</td>\n",
       "      <td>[-0.028409814, -0.057278637, -0.04101186, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>795</td>\n",
       "      <td>How is AWS Lambda@Edge different from using AW...</td>\n",
       "      <td>The difference is that API Gateway and Lambda ...</td>\n",
       "      <td>[0.012427445, -0.08264046, -0.05015783, -0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>What are some of the ideal use cases for R6g i...</td>\n",
       "      <td>R6g instances deliver significant price perfor...</td>\n",
       "      <td>[0.0057732402, -0.062491536, -0.02346015, 0.04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            pattern  \\\n",
       "268    269                              Why should I use EFA?   \n",
       "1261  1262  How do I know in which S3 Intelligent-Tiering ...   \n",
       "81      82      Will vCPU limits be available in all Regions?   \n",
       "794    795  How is AWS Lambda@Edge different from using AW...   \n",
       "195    196  What are some of the ideal use cases for R6g i...   \n",
       "\n",
       "                                               response  \\\n",
       "268   EFA brings the scalability, flexibility, and e...   \n",
       "1261  You can use Amazon S3 Inventory to report the ...   \n",
       "81    vCPU-based instance limits are available in al...   \n",
       "794   The difference is that API Gateway and Lambda ...   \n",
       "195   R6g instances deliver significant price perfor...   \n",
       "\n",
       "                                         ResponseVector  \n",
       "268   [-0.008393067, -0.043162365, -0.02907724, 0.02...  \n",
       "1261  [-0.008884707, -0.022729026, 0.010597382, 0.02...  \n",
       "81    [-0.028409814, -0.057278637, -0.04101186, 0.01...  \n",
       "794   [0.012427445, -0.08264046, -0.05015783, -0.016...  \n",
       "195   [0.0057732402, -0.062491536, -0.02346015, 0.04...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(input_keyword):\n",
    "    # model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    # input_keyword = \"Billing of Amazon EC2 systems begin and end?\"\n",
    "    vector_of_input_keyword = model.encode(input_keyword)\n",
    "\n",
    "    query = {\n",
    "        \"field\" : \"ResponseVector\",\n",
    "        \"query_vector\" : vector_of_input_keyword,\n",
    "        \"k\" : 3,\n",
    "        \"num_candidates\" : 1500, \n",
    "    }\n",
    "\n",
    "    res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n",
    "    results = res[\"hits\"][\"hits\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4759/576961223.py:13: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: Why should I use EFA? \n",
      "Response: EFA brings the scalability, flexibility, and elasticity of cloud to tightly coupled HPC applications. With EFA, tightly coupled HPC applications have access to lower and more consistent latency and higher throughput than traditional TCP channels, enabling them to scale better. EFA support can be enabled dynamically, on-demand on any supported EC2 instance without pre-reservation, giving you the flexibility to respond to changing business/workload priorities.\n",
      "Pattern: How do I get my data into S3 Intelligent-Tiering? \n",
      "Response: There are two ways to get data into S3 Intelligent-Tiering. You can directly PUT into S3 Intelligent-Tiering by specifying INTELLIGENT_TIERING in the x-amz-storage-class header or set lifecycle policies to transition objects from S3 Standard or S3 Standard-IA to S3 INTELLIGENT_TIERING.\n",
      "Pattern: Will vCPU limits be available in all Regions? \n",
      "Response: vCPU-based instance limits are available in all commercial AWS Regions.\n",
      "Pattern: When should I use Lambda@Edge? \n",
      "Response: Lambda@Edge is optimized for latency-sensitive use cases where your end viewers are distributed globally. All the information you need to make a decision should be available at the CloudFront edge, within the function and the request. This means that use cases where you are looking to make decisions on how to serve content based on user characteristics (e.g., location, client device, etc.) can now be executed and served close to your users without having to be routed back to a centralized server. \n",
      "Pattern: What are some of the ideal use cases for M6g instances? \n",
      "Response: M6g instances deliver significant performance and price performance benefits for a broad spectrum of general-purpose workloads such as application servers, gaming servers, microservices, mid-size databases, and caching fleets. Customers deploying applications built on open source software across the M instances will find the M6g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation.\n",
      "Pattern: How do I decide which S3 storage class to use? \n",
      "Response: The Amazon S3 Glacier storage classes are purpose-built for data archiving, providing you with the highest performance, most retrieval flexibility, and the lowest cost archive storage in the cloud. You can now choose from three archive storage classes optimized for different access pattern and storage duration. For archive data that needs immediate access, such as medical images, news media assets, or genomics data, choose the S3 Glacier Instant Retrieval storage class, an archive storage class that delivers the lowest cost storage with milliseconds retrieval. For archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, such as backup or disaster recovery use cases, choose S3 Glacier Flexible Retrieval, with retrieval in minutes or free bulk retrievals in 5 12 hours. To save even more on long-lived archive storage such as compliance archives and digital media preservation, choose S3 Glacier Deep Archive, the lowest cost storage in the cloud with data retrieval within 12 hours. All these storage classes provide multi-Availability Zone (AZ) resiliency by redundantly storing data on multiple devices and physically separated AWS Availability Zones in an AWS Region.  For data that has a lower resiliency requirement, you can reduce costs by selecting a single-AZ storage class, like S3 One Zone-Infrequent Access. If you have data residency or latency requirements that can't be met by an existing AWS Region, you can choose S3 on Outposts to store data on-premises.  You can learn more about these storage classes on the Amazon S3 Storage Classes page.\n",
      "Pattern: Do I need to enable backups for my DB Instance or is it done automatically? \n",
      "Response: By default, Amazon RDS enables automated backups of your DB instance with a 7-day retention period. If you would like to modify your backup retention period, you can do so using the RDS Console, the CreateDBInstance API (when creating a new DB Instance), or the ModifyDBInstance API (for existing instances). You can use these methods to change the RetentionPeriod parameter to any number from 0 (which will disable automated backups) to the desired number of days, up to 35. The value cannot be set to 0 if the DB instance is a source to Read Replicas. For more information on automated backups, please refer to the Amazon RDS User Guide. \n",
      "Pattern: Which volume type should I choose? \n",
      "Response: Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1 and io2) and General Purpose SSD (gp2 and gp3). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O pattern. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information, see the Amazon EBS overview.\n",
      "Pattern: Are reserved instances available for Multi-AZ deployments? \n",
      "Response: Yes. When you purchase a reserved instance, you can select the Multi-AZ option in the DB instance configuration available for purchase. In addition, if you are using a DB engine and license model that supports reserved instance size-flexibility, a Multi-AZ reserved instance will cover usage for two Single-AZ DB instances. \n",
      "Pattern: What is the Lambda Runtime Interface Emulator (RIE)? \n",
      "Response: The Lambda Runtime Interface Emulator is a proxy for the Lambda Runtime API,which allows customers to locally test their Lambda function packaged as a container image. It is a lightweight web server that converts HTTP requests to JSON events and emulates the Lambda Runtime API. It allows you to locally test your functions using familiar tools such as cURL and the Docker CLI (when testing functions packaged as container images). It also simplifies running your application on additional compute services. You can include the Lambda Runtime Interface Emulator in your container image to have it accept HTTP requests natively instead of the JSON events required for deployment to Lambda. This component does not emulate the Lambda orchestrator, or security and authentication configurations. The Runtime Interface Emulator is open sourced on GitHub. You can get started by downloading and installing it on your local machine. \n",
      "Pattern: How can I optimize costs for my application with fluctuating demand throughout the day? \n",
      "Response: Use a combination of Reserved Instances for baseline capacity and Spot Instances for handling fluctuations in demand. This hybrid approach optimizes costs for varying workloads.\n",
      "Pattern: Can I customize my access levels? \n",
      "Response: No. You can only use the three pre-defined access levels (READ/WRITE/READWRITE) that S3 Access Grants offers.\n",
      "Pattern: Do I have to pay for hibernating my Spot instance? \n",
      "Response: There is no additional charge for hibernating your instance beyond the EBS storage costs and any other EC2 resources you may be using. You are not charged instance usage fees once your instance is hibernated.\n",
      "Pattern: Can I still use/add more Previous Generation instances? \n",
      "Response: Yes. Previous Generation instances are still available as On-Demand, Reserved Instances, and Spot Instance, from our APIs, CLI and EC2 Management Console interface.\n",
      "Pattern: What is an AWS Region? \n",
      "Response: An AWS Region is a physical location around the world where AWS cluster data centers.  Each group of logical data centers within a Region is know as an Availability Zone (AZ). Each AWS Region consists of a minimum of three, isolated, and physically separate AZs within a geographic area. Unlike other cloud providers, who often define a Region as a single data center, the multiple AZ design of every AWS Region offers advantages for customers. Each AZ has independent power, cooling, and physical security and is connected via redundant, ultra-low-latency networks.\n"
     ]
    }
   ],
   "source": [
    "arr_of_actual_responses = rdf['response'].tolist()\n",
    "arr_of_predicted_responses = []\n",
    "\n",
    "for index, row in rdf.iterrows():\n",
    "    result = search(row[\"pattern\"])\n",
    "    print(f\"Pattern: {result[1]['_source']['pattern']} \")\n",
    "    print(f\"Response: {result[1]['_source']['response']}\")\n",
    "    arr_of_predicted_responses.append(result[1]['_source']['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EFA brings the scalability, flexibility, and elasticity of cloud to tightly coupled HPC applications. With EFA, tightly coupled HPC applications have access to lower and more consistent latency and higher throughput than traditional TCP channels, enabling them to scale better. EFA support can be enabled dynamically, on-demand on any supported EC2 instance without pre-reservation, giving you the flexibility to respond to changing business/workload priorities.', 'There are two ways to get data into S3 Intelligent-Tiering. You can directly PUT into S3 Intelligent-Tiering by specifying INTELLIGENT_TIERING in the x-amz-storage-class header or set lifecycle policies to transition objects from S3 Standard or S3 Standard-IA to S3 INTELLIGENT_TIERING.', 'vCPU-based instance limits are available in all commercial AWS Regions.', 'Lambda@Edge is optimized for latency-sensitive use cases where your end viewers are distributed globally. All the information you need to make a decision should be available at the CloudFront edge, within the function and the request. This means that use cases where you are looking to make decisions on how to serve content based on user characteristics (e.g., location, client device, etc.) can now be executed and served close to your users without having to be routed back to a centralized server. ', 'M6g instances deliver significant performance and price performance benefits for a broad spectrum of general-purpose workloads such as application servers, gaming servers, microservices, mid-size databases, and caching fleets. Customers deploying applications built on open source software across the M instances will find the M6g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation.', \"The Amazon S3 Glacier storage classes are purpose-built for data archiving, providing you with the highest performance, most retrieval flexibility, and the lowest cost archive storage in the cloud. You can now choose from three archive storage classes optimized for different access pattern and storage duration. For archive data that needs immediate access, such as medical images, news media assets, or genomics data, choose the S3 Glacier Instant Retrieval storage class, an archive storage class that delivers the lowest cost storage with milliseconds retrieval. For archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, such as backup or disaster recovery use cases, choose S3 Glacier Flexible Retrieval, with retrieval in minutes or free bulk retrievals in 5 12 hours. To save even more on long-lived archive storage such as compliance archives and digital media preservation, choose S3 Glacier Deep Archive, the lowest cost storage in the cloud with data retrieval within 12 hours. All these storage classes provide multi-Availability Zone (AZ) resiliency by redundantly storing data on multiple devices and physically separated AWS Availability Zones in an AWS Region.  For data that has a lower resiliency requirement, you can reduce costs by selecting a single-AZ storage class, like S3 One Zone-Infrequent Access. If you have data residency or latency requirements that can't be met by an existing AWS Region, you can choose S3 on Outposts to store data on-premises.  You can learn more about these storage classes on the Amazon S3 Storage Classes page.\", 'By default, Amazon RDS enables automated backups of your DB instance with a 7-day retention period. If you would like to modify your backup retention period, you can do so using the RDS Console, the CreateDBInstance API (when creating a new DB Instance), or the ModifyDBInstance API (for existing instances). You can use these methods to change the RetentionPeriod parameter to any number from 0 (which will disable automated backups) to the desired number of days, up to 35. The value cannot be set to 0 if the DB instance is a source to Read Replicas. For more information on automated backups, please refer to the Amazon RDS User Guide. ', 'Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1 and io2) and General Purpose SSD (gp2 and gp3). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O pattern. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information, see the Amazon EBS overview.', 'Yes. When you purchase a reserved instance, you can select the Multi-AZ option in the DB instance configuration available for purchase. In addition, if you are using a DB engine and license model that supports reserved instance size-flexibility, a Multi-AZ reserved instance will cover usage for two Single-AZ DB instances. ', 'The Lambda Runtime Interface Emulator is a proxy for the Lambda Runtime API,which allows customers to locally test their Lambda function packaged as a container image. It is a lightweight web server that converts HTTP requests to JSON events and emulates the Lambda Runtime API. It allows you to locally test your functions using familiar tools such as cURL and the Docker CLI (when testing functions packaged as container images). It also simplifies running your application on additional compute services. You can include the Lambda Runtime Interface Emulator in your container image to have it accept HTTP requests natively instead of the JSON events required for deployment to Lambda. This component does not emulate the Lambda orchestrator, or security and authentication configurations. The Runtime Interface Emulator is open sourced on GitHub. You can get started by downloading and installing it on your local machine. ', 'Use a combination of Reserved Instances for baseline capacity and Spot Instances for handling fluctuations in demand. This hybrid approach optimizes costs for varying workloads.', 'No. You can only use the three pre-defined access levels (READ/WRITE/READWRITE) that S3 Access Grants offers.', 'There is no additional charge for hibernating your instance beyond the EBS storage costs and any other EC2 resources you may be using. You are not charged instance usage fees once your instance is hibernated.', 'Yes. Previous Generation instances are still available as On-Demand, Reserved Instances, and Spot Instance, from our APIs, CLI and EC2 Management Console interface.', 'An AWS Region is a physical location around the world where AWS cluster data centers.  Each group of logical data centers within a Region is know as an Availability Zone (AZ). Each AWS Region consists of a minimum of three, isolated, and physically separate AZs within a geographic area. Unlike other cloud providers, who often define a Region as a single data center, the multiple AZ design of every AWS Region offers advantages for customers. Each AZ has independent power, cooling, and physical security and is connected via redundant, ultra-low-latency networks.']\n"
     ]
    }
   ],
   "source": [
    "# print(rdf['response'].tolist())\n",
    "print(arr_of_predicted_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.2\n"
     ]
    }
   ],
   "source": [
    "def precision_for_k(arr_of_actual_responses, arr_of_predicted_responses, k):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(arr_of_actual_responses)-1):\n",
    "        if (arr_of_actual_responses[i] == arr_of_predicted_responses[i]) :\n",
    "            \n",
    "            sum += 1\n",
    "        # else:\n",
    "            # print(f\"{arr_of_actual_responses[i]} !=== {arr_of_predicted_responses[i]}\")\n",
    "    precision = sum / k if k > 0 else 0\n",
    "    print(f\"precision : {precision}\")\n",
    "\n",
    "k = len(rdf.index)\n",
    "precision_for_k(arr_of_actual_responses, arr_of_predicted_responses, k)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
